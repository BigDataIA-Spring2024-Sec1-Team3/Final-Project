{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMPORT LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diagrams import Diagram, Cluster, Edge\n",
    "from diagrams.programming.language import Python\n",
    "from diagrams.custom import Custom\n",
    "from diagrams.aws.storage import S3\n",
    "from diagrams.aws.network import ELB\n",
    "from diagrams.aws.compute import EC2\n",
    "from diagrams.saas.analytics import Snowflake\n",
    "from diagrams.onprem.workflow import Airflow\n",
    "from diagrams.programming.framework import FastAPI\n",
    "from diagrams.digitalocean.compute import Docker\n",
    "from diagrams.onprem.database import Mongodb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust these Graphviz attributes to increase diagram size, node spacing, etc.\n",
    "graph_attr = {\n",
    "    \"fontsize\": \"14\"\n",
    "}\n",
    "\n",
    "filename = \"flow_diagram\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FLOW DIAGRAM CREATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_flow_diagram():\n",
    "    try:\n",
    "        with Diagram(\"Flow Diagram\", filename=filename, show=False, direction=\"LR\", graph_attr=graph_attr):\n",
    "            \n",
    "            linkedin = Custom(\"LinkedIn\",\"./input_icons/linkedin.png\")\n",
    "            indeed = Custom(\"Indeed\", \"./input_icons/indeed.png\")\n",
    "            with Cluster(\"Hourly pipleine\"):\n",
    "                # airflow1 = Airflow(\"Hourly Pipeline\")\n",
    "                job_scrape = Python(\"Job scrape\")\n",
    "                data_validation = Python(\"Data Validation\")\n",
    "                job_load = Python(\"Jobs load\")\n",
    "            \n",
    "            with Cluster(\"Hourly vectorize\"):\n",
    "                vectorize = Python(\"Embedding\")\n",
    "            \n",
    "            pinecone = Custom(\"Pinecone\", \"./input_icons/pinecone.png\")\n",
    "            snowflake = Snowflake(\"Snowflake\")\n",
    "                \n",
    "            linkedin >> job_scrape\n",
    "            indeed >> job_scrape\n",
    "            job_scrape >> data_validation >> job_load >> snowflake \n",
    "            snowflake >> vectorize >> pinecone\n",
    "            \n",
    "            with Cluster(\"Daily job update pipeline\"):\n",
    "                batch = Python(\"Data Batch\\n processing\")\n",
    "                status_update =Python(\"Status update\")\n",
    "              \n",
    "            snowflake >> Edge(label=\"Jobs fetch\") >> batch\n",
    "            batch >> Edge(label=\"URL pass\\n\") >> status_update\n",
    "            status_update >> Edge(label=\"Updated status\") >> snowflake\n",
    "            \n",
    "            user = Custom(\"User\", \"./input_icons/user.png\")\n",
    "            streamlit = Custom(\"UI\", \"./input_icons/streamlit.png\")\n",
    "            fastapi = FastAPI(\"Fast API\")\n",
    "            s3 = S3(\"Staging\")\n",
    "            \n",
    "            \n",
    "            user >> Edge(label = \"Uploads resume\") >> streamlit >> fastapi >> s3\n",
    "            streamlit >> Edge(label=\"\\n\\nTop 10 jobs\") >> user\n",
    "            \n",
    "            with Cluster(\"Pipeline\"):\n",
    "                pdf_extract = Python(\"\\nResume text\\n extract\")\n",
    "                vector = Python(\"embedding\")\n",
    "                similar_jobs = Python(\"Top 10 jobs\\nmatch\")\n",
    "                \n",
    "            mongo = Mongodb(\"Mongo\")\n",
    "            openai = Custom(\"OpenAi\", \"./input_icons/openai.png\")\n",
    "            \n",
    "            fastapi >> Edge(label=\"S3 path\") >> pdf_extract >> vector >> Edge(label=\"\\npinecone metadata\") >>similar_jobs\n",
    "            pdf_extract >> Edge(label=\"User portfolio\\n(text format)\") >> s3\n",
    "            vector >> pinecone\n",
    "            s3 >> Edge(label=\"fetch user portfolio\") >> vector\n",
    "            similar_jobs >> Edge(label=\"Resume mapping\") << mongo\n",
    "            fastapi >> Edge(label=\"User authentication\") << mongo\n",
    "            vector >> Edge(label=\"Embedding \") << openai\n",
    "            pinecone >> similar_jobs\n",
    "            similar_jobs >> openai\n",
    "\n",
    "      \n",
    "    except Exception as e:\n",
    "        print(\"Exception: \",e)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_flow_diagram()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
